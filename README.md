# Analyzing Polarization And Toxicity On Political Debate In Brazilian TikTok Videos Transcriptions
Source code of the paper "Analyzing Polarization And Toxicity On Political Debate In Brazilian TikTok Videos Transcriptions" for the Web Science 2023. 

You can read the paper [here](https://dl.acm.org/doi/10.1145/3578503.3583613)

# Citation
```
@inproceedings{10.1145/3578503.3583613,
author = {Vasconcellos, Paulo Henrique Santos and Lara, Pedro Di\'{o}genes de Almeida and Marques-Neto, Humberto Torres},
title = {Analyzing Polarization And Toxicity On Political Debate In Brazilian TikTok Videos Transcriptions},
year = {2023},
isbn = {9798400700897},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578503.3583613},
doi = {10.1145/3578503.3583613},
abstract = {With the rise of TikTok’s popularity, there is an opportunity to understand how political communication has been made on this platform based on short videos. In addition to understanding what topics and themes are discussed on TikTok, we also analyzed the polarization and toxic behavior of its users. However, this great opportunity brings a challenge as well. As TikTok is a video platform, the largest content information is in the video itself, so it is necessary to extract this information from video data and features. In this paper, we propose a methodology to extract topics from TikTok video transcriptions in order to identify polarization and toxicity in their contents, by using techniques that range from web crawling to speech recognition algorithms. By providing a robust audio cleaning pipeline, it’s possible to generate a less noisy dataset, by removing silence and music segments. We validate our methodology by practically applying it to create topics in order to identify signs of political polarization and toxicity in 8,329 Brazilian political TikTok videos, collected over the last two years. Our work shows that it is possible to extract coherent and meaningful topics from TikTok videos, even with the challenges spoken texts bring. We point out that topics related to religion and social classes contain a higher percentage of toxicity and polarization, as well as opposite hashtags, such as "direita" (Right-wing) and "esquerda" (Left-wing).},
booktitle = {Proceedings of the 15th ACM Web Science Conference 2023},
pages = {33–42},
numpages = {10},
keywords = {Topic Modeling, TikTok, Political Toxicity, Text Analysis, Political Polarization, Online Social Networks},
location = {Austin, TX, USA},
series = {WebSci '23}
}
```

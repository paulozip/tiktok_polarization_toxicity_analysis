{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from tqdm import tqdm\n",
    "\n",
    "WAV_OUTPUT_DIR = '../data/processed/wav/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-timing",
   "metadata": {},
   "source": [
    "# Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.read_csv('../data/processed/videos_with_segmented_audio.csv')\n",
    "df_videos.drop_duplicates(subset=['id'], inplace=True)\n",
    "df_videos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3ce28",
   "metadata": {},
   "source": [
    "# Checking what percentage of the video is made of music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a049556",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_segments_df = pd.read_csv('../data/processed/video_audio_segments.csv')\n",
    "audio_segments_df['total_duration'] = audio_segments_df['end'] - audio_segments_df['start']\n",
    "\n",
    "# Grouping by video_id and label\n",
    "grouped_audio_segments = audio_segments_df.groupby(['video_id', 'label']).agg({'total_duration': 'sum'})\n",
    "grouped_audio_segments = grouped_audio_segments.reset_index()\n",
    "\n",
    "videos_with_music = grouped_audio_segments.loc[grouped_audio_segments['label'] == 'music', ['video_id', 'total_duration']]\n",
    "videos_with_music.columns = ['video_id', 'total_music_duration']\n",
    "videos_with_music.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e745b9",
   "metadata": {},
   "source": [
    "## Merging dataframe with audio segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_videos_annotations = df_videos.merge(videos_with_music, left_on='id', right_on='video_id', how='left')\n",
    "df_merged_videos_annotations = df_merged_videos_annotations.drop(['video_id'], axis=1)\n",
    "\n",
    "# Calculating percentage of music in video\n",
    "df_merged_videos_annotations['total_music_duration'] = df_merged_videos_annotations['total_music_duration'].fillna(0)\n",
    "df_merged_videos_annotations['percentage_of_video_made_of_music'] = df_merged_videos_annotations['total_music_duration'] * 100.00 / df_merged_videos_annotations['duration']\n",
    "df_merged_videos_annotations.set_index('id', inplace=True)\n",
    "df_merged_videos_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c41e5",
   "metadata": {},
   "source": [
    "# Trimming audio containing only male and female voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbce3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_audios_with_voice = 0\n",
    "for video_id in tqdm(df_merged_videos_annotations.index):\n",
    "    video = df_merged_videos_annotations.loc[[video_id]]\n",
    "    video_id = video_id\n",
    "\n",
    "    video_filename = '../' + video['video_path'].values[0]\n",
    "\n",
    "    audio_voice_segments = audio_segments_df.loc[(audio_segments_df['video_id'] == video_id) & \n",
    "                                                 (audio_segments_df['label'].isin(['male', 'female']))].copy()\n",
    "    audio_voice_segments.loc[:, 'next_start'] = audio_voice_segments.loc[:, 'start'].shift(-1)\n",
    "\n",
    "    audio = AudioSegment.from_file(video_filename)\n",
    "    trimmed_audio_voices = []\n",
    "\n",
    "    audio_start = audio_voice_segments['start'].min() * 1000\n",
    "    for idx, row in audio_voice_segments.iterrows():\n",
    "        if row['next_start'] < row['end'] + 1:\n",
    "            continue\n",
    "\n",
    "        start = audio_start        \n",
    "        end = (row['end'] + 1) * 1000\n",
    "        if len(trimmed_audio_voices) == 0:\n",
    "            trimmed_audio_voices = audio[start:end]\n",
    "        else:\n",
    "            trimmed_audio_voices = trimmed_audio_voices + audio[start:end]\n",
    "\n",
    "        audio_start = row['next_start'] * 1000\n",
    "\n",
    "    if len(trimmed_audio_voices) > 0:\n",
    "        trimmed_audio_voices.export(f\"../data/audios/{video_id}.mp3\", format=\"mp3\")\n",
    "        successful_audios_with_voice += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-dinner",
   "metadata": {},
   "source": [
    "# Saving transcripted video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_videos_annotations.to_csv('../data/processed/transcripted_processed_videos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

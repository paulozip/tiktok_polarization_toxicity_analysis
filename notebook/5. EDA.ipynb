{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_transcripted = pd.read_csv('../data/processed/cleaned_transcripted_dataset.csv')\n",
    "df_cleaned_transcripted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40375f37",
   "metadata": {},
   "source": [
    "# S2T statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_tokens = []\n",
    "videos_lenght = []\n",
    "\n",
    "for video in df_cleaned_transcripted['transcription']:\n",
    "    video = str.lower(video)\n",
    "    videos_lenght.append(len(set(video.split())))\n",
    "    videos_tokens.append(len(video.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0420c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Tokens per video:', np.mean(videos_tokens))\n",
    "print('Median Tokens per video:', np.median(videos_tokens))\n",
    "print()\n",
    "print('Average Unique Tokens per video:', np.mean(videos_lenght))\n",
    "print('Median Unique Tokens per video:', np.median(videos_lenght))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac39028",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First video was created at:', df_cleaned_transcripted['create_time'].min())\n",
    "print('Last video was created at:', df_cleaned_transcripted['create_time'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-choice",
   "metadata": {},
   "source": [
    "# Commonly used hashtags\n",
    "What hashtags are used along with others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hashtags = df_cleaned_transcripted.loc[:, ['video_hashtags']].fillna('')\n",
    "for idx in range(len(df_hashtags)):\n",
    "    row = df_hashtags.loc[idx]\n",
    "    for hashtag in row['video_hashtags'].split(','):\n",
    "        if len(hashtag) == 0:\n",
    "            continue\n",
    "        hashtag = hashtag.strip()\n",
    "        df_hashtags.loc[idx, hashtag] = 1\n",
    "        \n",
    "df_hashtags = df_hashtags.drop('video_hashtags', axis=1)\n",
    "df_hashtags = df_hashtags.fillna(0)\n",
    "df_hashtags = df_hashtags.astype(int)\n",
    "df_hashtags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-houston",
   "metadata": {},
   "source": [
    "## Co-occurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence_matrix = df_hashtags.T.dot(df_hashtags)\n",
    "occurence_matrix['Total'] = occurence_matrix.sum(axis=0)\n",
    "occurence_matrix = occurence_matrix.sort_values(by='Total', ascending=False)\n",
    "occurence_matrix.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-hamilton",
   "metadata": {},
   "source": [
    "## Selecting K most used hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing TikTok's control hashtag\n",
    "occurence_matrix.drop(['fy', 'fypシ', 'fyp', 'foryou', 'viral', 'foryoupage'], axis=0, inplace=True)\n",
    "occurence_matrix.drop(['fy', 'fypシ', 'fyp', 'foryou', 'viral', 'foryoupage'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 30\n",
    "most_used_k_tags = occurence_matrix.iloc[:K]\n",
    "\n",
    "most_used_k_tags_index = most_used_k_tags.index.tolist() + ['Total']\n",
    "\n",
    "most_used_k_tags = most_used_k_tags.append(most_used_k_tags.sum(numeric_only=True), ignore_index=True) # Adding a 'Total' row at the end\n",
    "\n",
    "most_used_k_tags.index = most_used_k_tags_index\n",
    "\n",
    "most_common_k_tags = most_used_k_tags.T\\\n",
    "                                     .sort_values(by='Total', axis=0, ascending=False)\\\n",
    "                                     .loc[most_used_k_tags_index]\\\n",
    "                                     .index\n",
    "\n",
    "most_common_tags = most_used_k_tags[most_common_k_tags].drop('Total', axis=1)\n",
    "most_common_tags = most_common_tags.loc[most_common_k_tags].drop('Total')\n",
    "index_sort = np.argsort(np.diag(most_common_tags))[::-1]\n",
    "most_common_tags = most_common_tags.iloc[index_sort, index_sort]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-separate",
   "metadata": {},
   "source": [
    "## Generating Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92851943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing diagonal values\n",
    "most_common_tags_labels = most_common_tags.columns\n",
    "most_common_tags = most_common_tags.values.astype(float)\n",
    "most_common_tags[np.diag_indices_from(most_common_tags)] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65426f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing upper diagonal values\n",
    "mask = np.zeros_like(most_common_tags, dtype='bool')\n",
    "mask[np.triu_indices_from(mask)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af89ea0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,7))\n",
    "sns.heatmap(most_common_tags, \n",
    "            annot=True, \n",
    "            cmap='Reds', \n",
    "            fmt='.0f', \n",
    "            vmax=600, \n",
    "            xticklabels=most_common_tags_labels, \n",
    "            yticklabels=most_common_tags_labels, \n",
    "            mask=mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa4fa3",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Pairwise analysis\n",
    "How pairs of hashtags correlates with the topic assigned by BTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv('../data/processed/predictions_btm_whisper.csv')\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_lst = []\n",
    "pairwise_toxicity_df = pd.DataFrame()\n",
    "parsed_hashtags = []\n",
    "for pair in most_frequent_pairs:\n",
    "    pair = pair.split('/')\n",
    "    pair.sort()\n",
    "    pair_hashtag = '/'.join(pair)\n",
    "    a, b  = pair\n",
    "    \n",
    "    if pair_hashtag in parsed_hashtags:\n",
    "        continue\n",
    "        \n",
    "    pair_data = predictions_df.loc[\n",
    "        (predictions_df['video_hashtags'].str.contains(r'(\\b|^){}(\\b|$)'.format(a))) &\n",
    "        (predictions_df['video_hashtags'].str.contains(r'(\\b|^){}(\\b|$)'.format(b)))]\n",
    "    \n",
    "    pair_dict = {\n",
    "        'pair_hashtag': pair_hashtag,\n",
    "        'total_videos': len(pair_data),\n",
    "        'perc_total': len(pair_data) * 100 / len(df_cleaned_transcripted),\n",
    "        'perc_toxic_videos': pair_data['is_toxic'].sum() * 100 / len(pair_data)\n",
    "    }\n",
    "    \n",
    "    top_topics = pair_data['topic_btm'].value_counts().index[:3].values\n",
    "    pair_dict['top_topics'] = ', '.join(top_topics)\n",
    "    \n",
    "    pairwise_lst.append(pair_dict)\n",
    "    parsed_hashtags.append(pair_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_w_toxicity_df = pd.DataFrame.from_dict(pairwise_lst).drop_duplicates()\n",
    "pairwise_w_toxicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fec4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Percentage of most toxic hashtags\n",
    "top_10_toxic_hashtags = pairwise_w_toxicity_df\\\n",
    "                            .sort_values('perc_toxic_videos', ascending=False)\\\n",
    "                            .head(10)\\\n",
    "                            .sort_values('perc_toxic_videos')\n",
    "fig = px.bar(top_10_toxic_hashtags, y='pair_hashtag', x='perc_toxic_videos', color_discrete_sequence=['#c0392b'])\n",
    "fig.update_layout(\n",
    "    #title='<b>Top 10 toxic hashtag pairs</b><br>Percentage of toxic videos in most frequent hashtag pairs',\n",
    "    xaxis=dict(title='<b>% of toxic videos</b>'),\n",
    "    yaxis=dict(title='<b>Hashtag pair</b>')\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar((predictions_df.groupby('topic_btm')['is_toxic'].sum() * 100 / predictions_df.groupby('topic_btm')['id'].count()).sort_values(ascending=True).reset_index(), \n",
    "             y='topic_btm', \n",
    "             x=0,\n",
    "             color_discrete_sequence=['#c0392b'])\n",
    "fig.update_layout(\n",
    "    #title='<b>Percentage of toxic videos per topic<b>',\n",
    "    xaxis=dict(title='<b>% of toxic videos</b>'),\n",
    "    yaxis=dict(title='<b>Topic</b>')\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.loc[:, 'video_hashtags'] = predictions_df['video_hashtags'].str.replace('lefttiktok', 'leftiktok')\n",
    "predictions_df.loc[:, 'video_hashtags'] = predictions_df['video_hashtags'].str.replace('righttiktok', 'rightiktok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d9fdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def is_valid_hashtag(hashtag):\n",
    "    hashtag = hashtag.strip()\n",
    "    ignore_hashtags = ['fyp', 'fy', 'foryou', 'foryoupage', 'viral', '']\n",
    "    \n",
    "    if hashtag in ignore_hashtags:\n",
    "        return False\n",
    "    \n",
    "    if len(hashtag1) == 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "pairwise_dfs = []\n",
    "top_pairwise_keys = set()\n",
    "\n",
    "for topic in predictions_df['topic_btm'].unique():\n",
    "    topic_pairwise_hashtag_dict = {}\n",
    "    print(topic)\n",
    "    topic_data = predictions_df.loc[predictions_df['topic_btm'] == topic].dropna()\n",
    "    \n",
    "    for video_idx in range(len(topic_data)):\n",
    "        video = topic_data.iloc[video_idx]\n",
    "        video_hashtags = video['video_hashtags'].split(',')\n",
    "        \n",
    "        for hashtag1 in video_hashtags:\n",
    "            if is_valid_hashtag(hashtag1):\n",
    "                for hashtag2 in video_hashtags:\n",
    "                    if is_valid_hashtag(hashtag2):\n",
    "                        if hashtag1 != hashtag2:\n",
    "                            hashtag_pair = [hashtag1.strip(), hashtag2.strip()]\n",
    "                            hashtag_pair.sort()\n",
    "\n",
    "                            hashtag_pair = '/'.join(hashtag_pair)\n",
    "                            topic_pairwise_hashtag_dict[hashtag_pair] = topic_pairwise_hashtag_dict.get(hashtag_pair, 0) + .5\n",
    "\n",
    "    # Sorting, selecting the top 10 pairs, and appending the df to the list to be concatenated\n",
    "    sorted_topic_pairwise_hashtag_dict = dict(sorted(topic_pairwise_hashtag_dict.items(),key=lambda x:x[1],reverse = True))\n",
    "    pairwise_df = pd.DataFrame.from_dict(sorted_topic_pairwise_hashtag_dict, orient='index')\n",
    "    pairwise_df_index = pairwise_df.iloc[:10]\n",
    "    display(pairwise_df_index)\n",
    "    top_pairwise_keys.update(pairwise_df_index.index)\n",
    "    \n",
    "    pairwise_df.columns = [topic]\n",
    "    pairwise_dfs.append(pairwise_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
